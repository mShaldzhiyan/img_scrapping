{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import cloudscraper\n",
    "import shutil\n",
    "import time\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_to_dict(tile):\n",
    "    item = dict()\n",
    "    item['title'] = tile.findAll('a')[0]['title']\n",
    "    item['data-itemid'] = tile['data-itemid']\n",
    "    item['url'] = tile['data-monetate-producturl']\n",
    "    try:\n",
    "        item['colours'] = [a.find('img')['alt'] for a in tile.findAll('li')]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        item['colours'] = 'Exception'\n",
    "    return item"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_PERSON = \"deep/person\"\n",
    "FOLDER_NO_PERSON = \"deep/no_person\"\n",
    "FOLDER_TEST = \"deep\"\n",
    "def get_images(url:str, id:str):\n",
    "    scraper = cloudscraper.create_scraper(delay=2)\n",
    "    response = scraper.get(url)\n",
    "    bs = BeautifulSoup(response.content, 'html.parser')\n",
    "    imgs = bs.findAll('picture', attrs={'class': 'swiper-zoomable'})\n",
    "    img_urls = [a['data-highres-images'] for a in imgs]\n",
    "    for img_url in enumerate(img_urls):\n",
    "        response = scraper.get(img_url[1])\n",
    "        filename = f'{id}_{img_url[0]}.jpg'\n",
    "        if 'alternate' in img_url[1]:\n",
    "            dst_file = os.path.join(FOLDER_PERSON, filename)\n",
    "        elif 'lifestyle' in img_url[1]:\n",
    "            dst_file = os.path.join(FOLDER_NO_PERSON, filename)\n",
    "        else:\n",
    "            dst_file = os.path.join(FOLDER_TEST, filename)\n",
    "        with open(dst_file, \"wb\") as f:\n",
    "            f.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_images(url):\n",
    "    print('Getting items info')\n",
    "    tiles = []\n",
    "    for i in range(999):\n",
    "        scraper = cloudscraper.create_scraper(delay=10)\n",
    "        print(i*32)\n",
    "        url = url.replace('?', f'?start={i*32}&')\n",
    "        response = scraper.get(url)\n",
    "        if response.status_code == 403:\n",
    "            print('auth error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        product_tiles = soup.select('.product-tile')\n",
    "        t = [tile_to_dict(a) for a in product_tiles]\n",
    "        if len(t) == 0:\n",
    "            print('no tiles')\n",
    "            break\n",
    "        tiles.extend(t)\n",
    "    df = pd.DataFrame(tiles)\n",
    "    df = df.drop_duplicates(subset=['data-itemid'], keep='first').reset_index(drop=True)\n",
    "    print('Saving images')\n",
    "    for a in tqdm(zip(df.url, df['data-itemid']), total=len(df)):\n",
    "        get_images(a[0], a[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting items info\n",
      "0\n",
      "32\n",
      "64\n",
      "96\n",
      "'NoneType' object is not subscriptable\n",
      "128\n",
      "'NoneType' object is not subscriptable\n",
      "'NoneType' object is not subscriptable\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "URL = r\"https://www.ralphlauren.nl/en/men/clothing/hoodies-sweatshirts/10204?webcat=men%7Cclothing%7Cmen-clothing-hoodies-sweatshirts\"\n",
    "df = scrape_images(URL)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tiles = []\n",
    "# for i in range(999):\n",
    "#     scraper = cloudscraper.create_scraper(delay=10)\n",
    "#     print(i*32)\n",
    "#     url = URL.replace('?', f'?start={i*32}&')\n",
    "#     response = scraper.get(url)\n",
    "#     if response.status_code == 403:\n",
    "#         print('auth error')\n",
    "#         break\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "#     product_tiles = soup.select('.product-tile')\n",
    "#     t = [tile_to_dict(a) for a in product_tiles]\n",
    "#     if len(t) == 0:\n",
    "#         print('no tiles')\n",
    "#         break\n",
    "#     tiles.extend(t)\n",
    "# df = pd.DataFrame(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a in tqdm(zip(df.url, df['data-itemid']), total=len(df)):\n",
    "#     get_images(a[0], a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL = r\"https://www.ralphlauren.nl/en/men/clothing/hoodies-sweatshirts/10204?webcat=men%7Cclothing%7Cmen-clothing-hoodies-sweatshirts\"\n",
    "# scraper = cloudscraper.create_scraper(delay=10)\n",
    "# response = scraper.get(URL)\n",
    "# bs = BeautifulSoup(response.content, 'html.parser')\n",
    "# product_tiles = bs.select('.product-tile')\n",
    "# tiles = [tile_to_dict(a) for a in product_tiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f664ab14f881270f6cb738ada9cdc617a115279c45c5e08d23c40b7bda2df46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
